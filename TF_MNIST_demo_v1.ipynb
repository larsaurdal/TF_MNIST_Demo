{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import some python libraries.  The most important of course is the TensorFlow library itself.  We also need the os library for doing some file path computations.  Finally, the urllib library allows us to load data stored somewhere on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the new Tensorflow 1.0 API from Google to classify the MNIST handwritten digits dataset.\n",
    "More information about TensorFlow can be found at https://www.tensorflow.org/.  This demo is heavily based on material presented by Dandelion Mané (of Google) at the TensorFlow Dev Summit 2017 in his excellent talk: Hands-on TensorBoard (https://www.youtube.com/watch?v=eBbEDRsCmv4&index=4&list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv) ....very worth watching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to set up some file locations etc... #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we need to define a logging directory to be used in the experiments that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = 'logdir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the logdirectory if it doesn't exist. When start a cell with '!' in a jupyter notebook, we don't execute python-code anymore, but we are actually executing the command in a shell. So the below is equivalent to going to your shell and executing \"mkdir -p $LOGDIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file LOGDIR already exists.\n",
      "Error occurred while processing: LOGDIR.\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p LOGDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dandelion Mané has very kindly set up a GitHub gist (think of a gist as a simplified Github repo, it is just used for sharing small pieces of code and examples) with everything we need in terms of data, here is the path to this gist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GIST_URL = 'https://gist.githubusercontent.com/dandelionmane/4f02ab8f1451e276fea1f165a20336f1/raw/a20c87f5e1f176e9abf677b46a74c6f2581c7bd8/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the so called MNIST data (more info at http://yann.lecun.com/exdb/mnist/).  Notice that TensorFlow provides a function for loading these data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting logdir/data\\train-images-idx3-ubyte.gz\n",
      "Extracting logdir/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting logdir/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting logdir/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir = LOGDIR + 'data', one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dandelion Mané has kindly provided us with some data that we need to make the embedding demo work (more on this later...).  Basically we are loading a sprite and labels file for the embedding projector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logdir/sprite_1024.png', <http.client.HTTPMessage at 0x19072438>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(GIST_URL + 'labels_1024.tsv', LOGDIR + 'labels_1024.tsv')\n",
    "urllib.request.urlretrieve(GIST_URL + 'sprite_1024.png', LOGDIR + 'sprite_1024.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to define a few convenience functions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first function basically makes it simple to compose some information strings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_hparam_string(learning_rate, num_convs, num_fully_connected):\n",
    "    return 'LR {0} Conv layers {1} Fully connected layers {2}'.format(learning_rate, num_convs, num_fully_connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next function uses TensorFlow syntax to define a python function that sets up a convolutional layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, size_in, size_out, conv_size = 3, conv_stride = 1, pool_factor = 1, pool_stride = 1, name = \"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        # Initialize weights with a truncated normal distribution\n",
    "        w = tf.Variable(tf.truncated_normal([conv_size, conv_size, size_in, size_out], stddev = 0.1), name = \"W\")\n",
    "        # Set the biases to be constants\n",
    "        b = tf.Variable(tf.constant(0.1, shape = [size_out]), name = \"B\")\n",
    "        # Perform the actual convolution\n",
    "        conv = tf.nn.conv2d(input, w, strides = [1, conv_stride, conv_stride, 1], padding = \"SAME\")\n",
    "        # Apply a rectified linear unit to the convolution result\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        # Dump information to the summary process\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        # Apply maxpooling and return\n",
    "        return tf.nn.max_pool(act, ksize = [1, pool_factor, pool_factor, 1], strides = [1, pool_stride, pool_stride, 1], padding = \"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function defines a python function that sets up a fully connected layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(input, size_in, size_out, name = \"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        # Initialize weights with a truncated normal distribution\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev = 0.1), name = \"W\")\n",
    "        # Set the biases to be constants\n",
    "        b = tf.Variable(tf.constant(0.1, shape = [size_out]), name = \"B\")\n",
    "        # Apply a rectified linear unit to the output\n",
    "        act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "        # Dump information to the summary process\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        # Return\n",
    "        return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model for MNIST #\n",
    "Now let's see how we can create the MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup placeholders for the image data and reshape the data for display\n",
    "x = tf.placeholder(tf.float32, shape = [None, 784], name = \"x\")\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# Dump information to the summary process\n",
    "tf.summary.image('input', x_image, 6)\n",
    "\n",
    "# Setup placeholders for the label data\n",
    "y = tf.placeholder(tf.float32, shape = [None, 10], name = \"labels\")\n",
    "\n",
    "# Define network with three convolutional layers and two fully connected layer\n",
    "conv1 = conv_layer(x_image, 1,  32, conv_size = 5, conv_stride = 1, pool_factor = 2, pool_stride = 2, name = \"conv1\")\n",
    "conv2 = conv_layer(conv1,  32,  64, conv_size = 5, conv_stride = 1, pool_factor = 2, pool_stride = 2, name = \"conv2\")\n",
    "\n",
    "# Flatten to prepare for the fully connected layers\n",
    "#flattened = tf.reshape(conv_out, [-1, 28 * 28 * 128])\n",
    "flattened = tf.reshape(conv2, [-1, 7 * 7 * 64])\n",
    "\n",
    "# Define fully connected layers\n",
    "#fc1 = fc_layer(flattened, 28 * 28 * 128, 1024, \"fc1\")\n",
    "feature_layer_size = 1024\n",
    "fc1 = fc_layer(flattened, 7 * 7 * 64, feature_layer_size, \"fc1\")\n",
    "\n",
    "logits = fc_layer(fc1, feature_layer_size, 10, \"fc2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining loss and optimizer #\n",
    "We here use the cross-entropy loss, which is commonly used for classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross-entropy loss\n",
    "with tf.name_scope(\"xent\"):\n",
    "    xent = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y), name = \"xent\")\n",
    "    tf.summary.scalar(\"xent\", xent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the optimization. We here use a optimization method called [ADAM](https://arxiv.org/pdf/1412.6980.pdf). This is a version of stochastic gradient descent (SGD) which tries to adjust the step size dynamically. Note that we don't even have to figure out the derivatives, TensorFlow propagates down the graph without any supervision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a learning rate\n",
    "learning_rate = 1E-4\n",
    "\n",
    "# Then define train operations - nothing runs yet, we are just defining the execution graph!\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to check how many errors we make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all summaries into one chunk\n",
    "summ = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a way to visualize the features you are learning. Our features are the layer where we make our predictions from. As the network is learning, the feature vectors of the different classes should be separated in space. This is only for visualization purposes, it will not affect training. (As you will later see there seems to be some mismatch in the indexing of the images...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then prepare for showing the embedding\n",
    "embedding_input = fc1 # take input from the last fully connected layers before prediction\n",
    "embedding_size = 1024\n",
    "\n",
    "embedding = tf.Variable(tf.zeros([1024, embedding_size]), name = \"test_embedding\")\n",
    "assignment = embedding.assign(embedding_input)\n",
    "\n",
    "\n",
    "config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "embedding_config = config.embeddings.add()\n",
    "embedding_config.tensor_name = embedding.name\n",
    "embedding_config.sprite.image_path = LOGDIR + 'sprite_1024.png'\n",
    "embedding_config.metadata_path = LOGDIR + 'labels_1024.tsv'\n",
    "    \n",
    "# Specify the width and height of a single thumbnail.\n",
    "embedding_config.sprite.single_image_dim.extend([28, 28])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start executing #\n",
    "Up until now have just been setup, telling TensorFlow what we want to do. To actually do something we need to create a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# All variables must be initialized! Now we actually start executing something\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "hparam = make_hparam_string(learning_rate, 2, 2) # create a string to add to the name of the logdir\n",
    "writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "\n",
    "writer.add_graph(sess.graph) # add graph for visualization\n",
    "tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config) # add embedding to visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets launch a TensorBoard server so we can visualize what happens. \n",
    "Go to your shell and enter the ouput of the command below as a command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir logdir/\n"
     ]
    }
   ],
   "source": [
    "! echo tensorboard --logdir $LOGDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in your webbrowser navigate to localhost:6006 (i.e. write \"localhost:6006\" in the address bar).\n",
    "You may also use the provided bookmark in the virtual machine! It's only the graphs section that contains any information yet! Try to right-clik on the \"train\" label and remove it from the main graph. You will now get a clearer picture.\n",
    "\n",
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver() # use to checkpoint the model\n",
    "\n",
    "# Now train for 2501 iterations\n",
    "for i in range(2501):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i % 5 == 0:\n",
    "        [train_accuracy, s] = sess.run([accuracy, summ], feed_dict = {x: batch[0], y: batch[1]})\n",
    "        writer.add_summary(s, i)\n",
    "    if i % 500 == 0:\n",
    "        sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]}) \n",
    "        saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to TensorBoard and explore! We have here plotted only the training loss and accuracy. What is a possible issue with this? Can you extend this to also plot the validation accuracy? (Hint: you may need a second \"writer\")! You may e.g. use the mnist.test.images dataset for validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also try a different learning rate, and see if that affects the results. Or change the number of layers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
